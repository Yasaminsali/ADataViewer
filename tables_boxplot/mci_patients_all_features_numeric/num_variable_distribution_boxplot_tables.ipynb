{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [pd.read_csv(file, sep=',') for file in sorted(glob.glob('../../feature_tables' + \"/*.\"+'csv'))]\n",
    "modalities = [file.split(\".\")[0] for file in sorted(os.listdir('../../feature_tables'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all modalities as a dataframe\n",
    "all_features = dict()\n",
    "\n",
    "for modal, df in zip(modalities, dataframes):\n",
    "    table = modal.split(\" - \")[1]\n",
    "    all_features[table] = df\n",
    "    \n",
    "# drop irrelevant columns    \n",
    "for moda in all_features:\n",
    "    all_features[moda].drop(columns=['CURIE', 'Definition', 'Synonyms'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the modalities into a dataframe \n",
    "merged = pd.concat(all_features, ignore_index=True)\n",
    "\n",
    "# replace the \"no total score\" as the test was performed but the total score was not reported \n",
    "merged.replace({\"No total score.\": np.nan}, inplace=True)\n",
    "\n",
    "# fill all the nan cells with 0\n",
    "merged.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank 2 is taboo\n",
    "numeric_df = merged.loc[(merged.Rank!=1) & (merged.Rank!=2)] # select the features that are numerical measurements \n",
    "categoric_df = merged.loc[(merged.Rank==1) & (merged.Rank!=2)] # select the features that are categorical measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the merged file for every cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [pd.read_csv(file, index_col=0, low_memory=False) for file in sorted(glob.glob('../../cohort_studies_full_data/' + \"/*.\"+'csv'))]\n",
    "cohorts = [file.split(\".\")[0] for file in sorted(os.listdir('../../cohort_studies_full_data/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all modalities as a dataframe\n",
    "cohort_studies = dict()\n",
    "\n",
    "for cohort, dataset in zip(cohorts, datasets):\n",
    "    cohort_n = cohort.split(\"_MERGE\")[0]\n",
    "    # reduce to BL visit and MCI participants\n",
    "    cohort_studies[cohort_n] = dataset.loc[(dataset['Months']==0) & (dataset['Diagnosis'].astype(str)=='MCI')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the index column consistent among the cohort dataframes\n",
    "for cohort in cohort_studies:\n",
    "    if cohort!='JADNI':\n",
    "        cohort_studies[cohort]['ID'] = cohort_studies[cohort].index\n",
    "        cohort_studies[cohort] = cohort_studies[cohort].reset_index().set_index('ID')\n",
    "        cohort_studies[cohort].dropna(axis=1, how='all', inplace=True) # drop columns with all NAN entries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funtion: extracting the reported values for every available feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df_dict, feature_df, result_dict):\n",
    "    \"\"\"make a dictionary containing dictionaries of each feature, the values of the inner dictionary are the \n",
    "    measurements for every available feature in each cohort study\"\"\"\n",
    "    \n",
    "    for feature in feature_df.Feature:\n",
    "        \n",
    "        # take columns that are same name as cohorts\n",
    "        for cohort in feature_df.columns.intersection(df_dict.keys()):\n",
    "            # select the feature name according to the respective cohort\n",
    "            feat = feature_df.loc[feature_df['Feature']==feature, cohort].item()\n",
    "            \n",
    "            # in the cells containing \",\" there are multiple features mapped \n",
    "            # if there is no comma that means the mapping are 1 to 1\n",
    "            # the value 0 represent the absence of the feature in the respective cohort\n",
    "            if (feat!=0) and (\", \" not in feat):\n",
    "                flag = False\n",
    "\n",
    "                # in some cases we have multiple targets features for the mapping, we prioritize the 100 match if available\n",
    "                for col in df_dict[cohort].columns:\n",
    "\n",
    "                    if feat==col:\n",
    "                        flag = True # if the 100% match was found \n",
    "                        l = list(df_dict[cohort][col].dropna())\n",
    "\n",
    "                        # when there are measurements available for the features shuffle and store them \n",
    "                        if len(l)!=0:\n",
    "                            result_dict[feature][feature + \".\" + cohort] = sample(l, len(l))\n",
    "\n",
    "                    elif (feat in col) and (flag==False):\n",
    "                        l = list(df_dict[cohort][col].dropna())\n",
    "\n",
    "                         # when there are measurements available for the features shuffle and store them \n",
    "                        if len(l)!=0:\n",
    "                            result_dict[feature][feature + \".\" + cohort] = sample(l, len(l))\n",
    "                \n",
    "\n",
    "            # in the cells containing \",\" there are multiple features mapped\n",
    "            # when there is multiple, take the second one\n",
    "            # the value 0 represent the absence of the feature in the respective cohort\n",
    "            elif (feat!=0) and (\", \" in feat):\n",
    "                # select the feature name according to the respective cohort\n",
    "                feat_n = feature_df.loc[feature_df['Feature']==feature, cohort].item().split(\", \")[1]\n",
    "                flag = False\n",
    "                    \n",
    "                # in some cases we have multiple targets features for the mapping, we prioritize the 100 match if available\n",
    "                for col in df_dict[cohort].columns:\n",
    "\n",
    "                    if feat_n==col:\n",
    "                        flag = True # if the 100% match was found \n",
    "                        l = list(df_dict[cohort][col].dropna())\n",
    "\n",
    "                        # when there are measurements available for the features shuffle and store them\n",
    "                        if len(l)!=0:\n",
    "                            result_dict[feature][feature + \".\" + cohort] = sample(l, len(l))\n",
    "\n",
    "                    elif (feat_n in col) and (flag==False):\n",
    "                        l = list(df_dict[cohort][col].dropna())\n",
    "\n",
    "                        # when there are measurements available for the features shuffle and store them\n",
    "                        if len(l)!=0:\n",
    "                            result_dict[feature][feature + \".\" + cohort] = sample(l, len(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary of dictionaries to store the results\n",
    "result = dict()\n",
    "\n",
    "# select the target features as outer dictionary's keys\n",
    "for feat in numeric_df.Feature:\n",
    "    avai_cohorts = dict()\n",
    "    \n",
    "    for cohort in numeric_df.columns.intersection(cohort_studies.keys()):\n",
    "        \n",
    "        # target feature names + the feature names for each cohort as inner dictionary's keys\n",
    "        if numeric_df.loc[numeric_df.Feature == feat, cohort].item()!=0:\n",
    "            avai_cohorts[feat + \".\" + cohort] = []\n",
    "            \n",
    "    result[feat]= avai_cohorts\n",
    "\n",
    "# call the function to generate the tables for boxplots\n",
    "extract_features(cohort_studies, numeric_df, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results into tsv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aibl did not report the age of the participnats, they reported the date of birth\n",
    "del result['Age']['Age.AIBL']\n",
    "del result['Age']['Age.ABVIB'] #only month and year of birth was reported \n",
    "\n",
    "# Certain measurements were collected as values in some cohorts and as categorical in others\n",
    "# Remove the ones that are categorical as we can not plot them\n",
    "del result['PiB PET']['PiB PET.AIBL'] # Positive, Negative\n",
    "del result['AV45 PET']['AV45 PET.AIBL'] # Positive, Negative\n",
    "del result['AV45 PET']['AV45 PET.NACC'] # Abnormally elevated amyloid on PET: 0=No, 1=Yes, 8=Unknown/not assessed\n",
    "del result['AV45 PET']['AV45 PET.EMIF'] # 0.0 and 1.0\n",
    "\n",
    "#convert each feature dictionary into a dataframe and save it as csv file \n",
    "for i in result:\n",
    "    \n",
    "    if (i==\"Age\") or (i==\"Education\"):\n",
    "        \n",
    "        for j in result[i]: \n",
    "            result[i][j] = list(map(int, result[i][j]))\n",
    "        \n",
    "    df = pd.DataFrame.from_dict(result[i], orient='index').transpose()\n",
    "    df.index.name = 'Participant number'\n",
    "    df.dropna(how='all', axis=1, inplace=True)\n",
    "    \n",
    "    if df.empty==False:\n",
    "        df.to_csv(f\"{i}.tsv\", sep='\\t', index_label='Participant number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
