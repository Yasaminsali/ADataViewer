{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import os\n",
    "import glob\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the CSV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [pd.read_csv(file, sep=',') for file in sorted(glob.glob('../feature_tables' + \"/*.\"+'csv'))]\n",
    "modalities = [file.split(\".\")[0] for file in sorted(os.listdir('../feature_tables'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all modalities as a dataframe\n",
    "all_features = dict()\n",
    "\n",
    "for modal, df in zip(modalities, dataframes):\n",
    "    table = modal.split(\" - \")[1]\n",
    "    all_features[table] = df\n",
    "    \n",
    "# drop irrelevant columns    \n",
    "for moda in all_features:\n",
    "    all_features[moda].drop(columns=['CURIE', 'Definition', 'Synonyms'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all the files for every cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [pd.read_csv(file, index_col=0, low_memory=False) for file in sorted(glob.glob('../cohort_studies_full_data/' + \"/*.\"+'csv'))]\n",
    "cohorts = [file.split(\".\")[0] for file in sorted(os.listdir('../cohort_studies_full_data/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all modalities as a dataframe\n",
    "cohort_studies = dict()\n",
    "all_cohort_names = list() # save  a list of cohort names\n",
    "\n",
    "for cohort, dataset in zip(cohorts, datasets):\n",
    "    cohort_n = cohort.split(\"_MERGE\")[0]\n",
    "    all_cohort_names.append(cohort_n)\n",
    "    cohort_studies[cohort_n] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the index column consistent among the cohort dataframes\n",
    "for cohort in cohort_studies:\n",
    "    if cohort!='JADNI':\n",
    "        cohort_studies[cohort]['ID'] = cohort_studies[cohort].index\n",
    "        cohort_studies[cohort] = cohort_studies[cohort].reset_index().set_index('ID')\n",
    "        cohort_studies[cohort].dropna(axis=1, how='all', inplace=True) # drop columns with all NAN entries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the total number of patients for each mapped feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patients_per_feature(feature_df, cohort_df, result_df):\n",
    "    \"\"\"read every cohort study dataframe from a dictionary of dataframes and check the number of participants\n",
    "    that have measurements for every mapped feature. Return a dictionary of dataframe with modalities under \n",
    "    which we mapped the features. Note: the number of participants are normalized by the totol number \n",
    "    of participants at the baseline visit (i.e. Number of participant|number of participant/total).\n",
    "    \n",
    "    Note: while looking for a certain feature in a dataset there is a possibility that we would find multiple\n",
    "    columns. We used substring search as the mapping features are the original name of the columns in the dataset\n",
    "    but while merging the tables some features got a suffix. For example: if we search for AGE in ADNI.columns, \n",
    "    we would find  AGE, IMAGEUID_x, MOTHAGE, MOTHSXAGE, FATHAGE, FATHSXAGE, SIBAGE, SIBSXAGE, IMAGEUID_y. \n",
    "    Thus, we first look for AGE and if it could not be found then look for substring matches.\"\"\"\n",
    "\n",
    "    for modality in result_df.keys():\n",
    "        result = result_df[modality]\n",
    "        \n",
    "        # check the intersecton to select the dataframes that exist in both dictionaries (all dataframe and mapping dictionaries)\n",
    "        for cohort in feature_df[modality].columns.intersection(cohort_df.keys()):\n",
    "            total = len(cohort_df[cohort].loc[cohort_df[cohort]['Months']==0].index.unique()) # total number of participants at baseline visit\n",
    "            \n",
    "            # select the features that were mapped for each cohort\n",
    "            for feature in feature_df[modality][cohort].loc[feature_df[modality][cohort].notna()]:\n",
    "\n",
    "                # if there is a comma it means there are two features mapped to one feature\n",
    "                # if there is not a comma then the features are mepped one to one\n",
    "                if \",\" not in feature:\n",
    "                    # we have multiple targets for certain features in the columns, we look for 100% match first\n",
    "                    flag=False \n",
    "\n",
    "                    # check the columns of each cohort study\n",
    "                    for col in cohort_df[cohort].columns:\n",
    "\n",
    "                        # if we cannot find the column name, there is chance the column names have a suffix\n",
    "                        if feature==col:\n",
    "                            flag=True # if we found the 100% match\n",
    "                            visits = list(Counter(cohort_df[cohort]['Months'].loc[cohort_df[cohort]['Months'].notna()])) # make a list of all visits for each cohort\n",
    "                    \n",
    "                            # for every visit calculate the number of participant for every feature and normilize it \n",
    "                            for vis in visits:\n",
    "                                col_new = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                                patient = len(cohort_df[cohort].loc[cohort_df[cohort]['Months']==vis][col].dropna().index.unique())\n",
    "                                result.loc[(result.index==cohort) & (result.Months==vis), col_new] = str(patient) + \"|\" + str(round(patient/total, 3))\n",
    "                                \n",
    "                        # when the feature was not found, search the columns using the substring matching\n",
    "                        elif (feature in col) & (flag==False):\n",
    "                            visits = list(Counter(cohort_df[cohort]['Months'].loc[cohort_df[cohort]['Months'].notna()])) # make a list of all visits for each cohort\n",
    "\n",
    "                            # for every visit calculate the number of participant for every feature and normilize it \n",
    "                            for vis in visits:\n",
    "                                col_new = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                                patient = len(cohort_df[cohort].loc[cohort_df[cohort]['Months']==vis][col].dropna().index.unique())\n",
    "                                result.loc[(result.index==cohort) & (result.Months==vis), col_new] = str(patient) + \"|\" + str(round(patient/total, 3))\n",
    "\n",
    "                # if there is a comma it means there are two features mapped to one feature\n",
    "                elif \",\" in feature:\n",
    "                    # we have multiple targets for certain features in the columns, we look for 100% match first\n",
    "                    flag=False\n",
    "\n",
    "                    # check the columns of each cohort study\n",
    "                    for col in cohort_df[cohort].columns:\n",
    "\n",
    "                        # if we cannot find the column name, there is chance the column names have a suffix\n",
    "                        if feature.split(\", \")[0]==col:\n",
    "                            flag=True # if we found the 100% match\n",
    "                            visits = list(Counter(cohort_df[cohort]['Months'].loc[cohort_df[cohort]['Months'].notna()])) # make a list of all visits for each cohort\n",
    "\n",
    "                            # for every visit calculate the number of participant for every feature and normilize it \n",
    "                            for vis in visits:\n",
    "                                col_new = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                                patient = len(cohort_df[cohort].loc[cohort_df[cohort]['Months']==vis][col].dropna().index.unique())\n",
    "                                result.loc[(result.index==cohort) & (result.Months==vis), col_new] = str(patient) + \"|\" + str(round(patient/total, 3))\n",
    "                                \n",
    "                        # when the feature was not found, search the columns using the substring matching\n",
    "                        elif (feature.split(\", \")[0] in col) & (flag==False):\n",
    "                            visits = list(Counter(cohort_df[cohort]['Months'].loc[cohort_df[cohort]['Months'].notna()])) # make a list of all visits for each cohort\n",
    "\n",
    "                            # for every visit calculate the number of participant for every feature and normilize it \n",
    "                            for vis in visits:\n",
    "                                col_new = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                                patient = len(cohort_df[cohort].loc[cohort_df[cohort]['Months']==vis][col].dropna().index.unique())\n",
    "                                result.loc[(result.index==cohort) & (result.Months==vis), col_new] = str(patient) + \"|\" + str(round(patient/total, 3))\n",
    "                                \n",
    "    # drop the rows that contain nan every column except the visit number(i.e. Months) column                        \n",
    "    for moda in result_df:\n",
    "        result_df[moda].replace({\"0|0.0\": np.nan}, inplace=True) # replace the entries that are zero with NAN, the feature exist but not for that visit\n",
    "        subset_cols = list() # make a list of all columns but the visit as it is never NAN\n",
    "\n",
    "        for i in result_df[moda].columns:\n",
    "\n",
    "            if i!='Months':\n",
    "                subset_cols.append(i)\n",
    "\n",
    "        # drop rows with NAN entries for every column\n",
    "        result_df[moda].dropna(how='all', subset=subset_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_exist(feature_df, cohort_df, result_df):\n",
    "    \"\"\" check whether evey mapped feature exist in the respective cohort and rank it with \"1\" and if it does not exist \n",
    "    then rank that cell with \"0\". Return two dataframes one showing only the features that did not exist in the dataframe and \n",
    "    a complete one with both ranks.\n",
    "    \n",
    "    Note: while looking for a certain feature in a dataset there is a possibility that we would find multiple\n",
    "    columns. We used substring search as the mapping features are the original name of the columns in the dataset\n",
    "    but while merging the tables some features got a suffix. For example: if we search for AGE in ADNI.columns, \n",
    "    we would find  AGE, IMAGEUID_x, MOTHAGE, MOTHSXAGE, FATHAGE, FATHSXAGE, SIBAGE, SIBSXAGE, IMAGEUID_y. \n",
    "    Thus, we first look for AGE and if it could not be found then look for substring matches.\"\"\"\n",
    "    \n",
    "    # make an empty dataframe for storing the features that do not exist in the actual dataset\n",
    "    nonexistence = pd.DataFrame(columns=['cohort', 'feature'])\n",
    "\n",
    "    for modality in result_df.keys():\n",
    "        result = result_df[modality]\n",
    "\n",
    "        # check the intersecton to select the dataframes that exist in both dictionaries (all dataframe and mapping dictionaries)\n",
    "        for cohort in feature_df[modality].columns.intersection(cohort_df.keys()):\n",
    "\n",
    "            # select the features that were mapped for each cohort\n",
    "            for feature in feature_df[modality][cohort].loc[feature_df[modality][cohort].notna()]:\n",
    "                \n",
    "                # if there is a comma it means there are two features mapped to one feature\n",
    "                # if there is not a comma then the features are mepped one to one\n",
    "                if \",\" not in feature:\n",
    "                    # we have multiple targets for certain features in the columns, we look for 100% match first\n",
    "                    flag=False\n",
    "                    ind = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                    result.loc[ind, cohort] = 0 # fist write zero for every feature that we mapped in result dataframes\n",
    "\n",
    "                    # check the columns of each cohort study\n",
    "                    for col in cohort_df[cohort].columns:\n",
    "\n",
    "                        if feature==col:\n",
    "                            flag=True # if we found the 100% match\n",
    "                            ind = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                            result.loc[ind, cohort] = 1 # store rank one where the feature exist in the cohort dataset\n",
    "                            \n",
    "                        elif (feature in col) & (flag==False):\n",
    "                            ind = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                            result.loc[ind, cohort] = 1 # store rank one where the feature exist in the cohort dataset\n",
    "                \n",
    "                # if there is a comma it means there are two features mapped to one feature\n",
    "                else:\n",
    "                    # we have multiple targets for certain features in the columns, we look for 100% match first\n",
    "                    flag=False\n",
    "                    ind = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                    result.loc[ind, cohort] = 0 # fist write zero for every feature that we mapped in result dataframes\n",
    "                    feat1 = feature.split(\", \")[0] # split the mapped features\n",
    "                    feat2 = feature.split(\", \")[1]\n",
    "\n",
    "                    # check the columns of each cohort study\n",
    "                    for col in cohort_df[cohort].columns:\n",
    "\n",
    "                        # if one feature exist so does the other as these features are related\n",
    "                        if (feat1==col) or (feat2==col):\n",
    "                            flag=True # if we found the 100% match\n",
    "                            ind = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                            result.loc[ind, cohort] = 1 # store rank one where the feature exist in the cohort dataset\n",
    "                        \n",
    "                        elif (feat1 in col) or (feat2 in col) & (flag==False):\n",
    "                            ind = feature_df[modality].loc[feature_df[modality][cohort]==feature, 'Feature']\n",
    "                            result.loc[ind, cohort] = 1 # store rank one where the feature exist in the cohort dataset\n",
    "                            \n",
    "                            \n",
    "    # from the result dataframe select the features that are rank zero and write it into another dataframe\n",
    "    for moda in result_df:\n",
    "        \n",
    "        for col in result_df[moda].columns:\n",
    "            bad = result_df[moda].loc[result_df[moda][col]==0].index.to_list() # find the nonexistence features\n",
    "            \n",
    "            # if there is at least one entry with the rank zero for each dataframe\n",
    "            if len(bad)!=0:\n",
    "                \n",
    "                for i in bad:\n",
    "                    bad_feat = feature_df[moda].loc[feature_df[moda]['Feature']==i, col].item()\n",
    "                    nonexistence = nonexistence.append({'cohort': col, 'feature': bad_feat}, ignore_index=True)          \n",
    "    \n",
    "                    \n",
    "    return nonexistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patient_measurment_availability(features, dataset, result_df):\n",
    "    \"\"\" write a dictionary of cohort studies where each key represents the respective cohort and value of that key\n",
    "    is a dataframe with patients as rows and all mapped features as columns. check for every patient whether the measurments\n",
    "    were collected at any vist of the study. store rank '1' were the measurement exist for that participant.\n",
    "    \n",
    "    Note: while looking for a certain feature in a dataset there is a possibility that we would find multiple\n",
    "    columns. We used substring search as the mapping features are the original name of the columns in the dataset\n",
    "    but while merging the tables some features got a suffix. For example: if we search for AGE in ADNI.columns, \n",
    "    we would find  AGE, IMAGEUID_x, MOTHAGE, MOTHSXAGE, FATHAGE, FATHSXAGE, SIBAGE, SIBSXAGE, IMAGEUID_y. \n",
    "    Thus, we first look for AGE and if it could not be found then look for substring matches.\"\"\"\n",
    "        \n",
    "    for cohort in dataset:\n",
    "        df = dataset[cohort]\n",
    "        \n",
    "        # take the patient ids from the cohort as index column for the results dataframe\n",
    "        result_df[cohort]['ID'] = df.index.unique() \n",
    "        result_df[cohort].set_index('ID', inplace=True)\n",
    "        \n",
    "        # for every feature find the mapped feature for the respective dataframe\n",
    "        for i in result_df[cohort].columns:\n",
    "            the_col = features.loc[features['Feature']==i, cohort].values[0]\n",
    "            \n",
    "            # if there is a comma it means there are two features mapped to one feature\n",
    "            # if there is not a comma then the features are mepped one to one\n",
    "            if \", \" not in the_col:\n",
    "                # we have multiple targets for certain features in the columns, we look for 100% match first\n",
    "                flag=False\n",
    "\n",
    "                for colu in df.columns:\n",
    "                    \n",
    "                    # if we cannot find the column name, there is chance the column names have a suffix\n",
    "                    if the_col==colu:\n",
    "                        flag=True # if we found the 100% match\n",
    "                        sub_df = df.loc[df[colu].notna(), colu]\n",
    "\n",
    "                        for patient in sub_df.index:\n",
    "                            result_df[cohort].loc[patient, i] = 1 # rank one for the patients that have measurements for the feature\n",
    "                    \n",
    "                    # when the feature was not found, search the columns using the substring matching\n",
    "                    elif (the_col in colu) & (flag==False):\n",
    "                        sub_df = df.loc[df[colu].notna(), colu]\n",
    "\n",
    "                        for patient in sub_df.index:\n",
    "                            result_df[cohort].loc[patient, i] = 1 # rank one for the patients that have measurements for the feature\n",
    "                            \n",
    "            # if there is a comma it means there are two features mapped to one feature\n",
    "            elif \", \" in the_col:\n",
    "                # we have multiple targets for certain features in the columns, we look for 100% match first\n",
    "                flag=False\n",
    "                \n",
    "                for colu in df.columns:\n",
    "                    \n",
    "                    # if we cannot find the column name, there is chance the column names have a suffix\n",
    "                    if the_col.split(\", \")[0]==colu:\n",
    "                        flag=True # if we found the 100% match\n",
    "                        sub_df = df.loc[df[colu].notna(), colu]\n",
    "\n",
    "                        for patient in sub_df.index:\n",
    "                            result_df[cohort].loc[patient, i] = 1 # rank one for the patients that have measurements for the feature\n",
    "                    \n",
    "                    # when the feature was not found, search the columns using the substring matching\n",
    "                    elif (the_col.split(\", \")[0] in colu) & (flag==False):\n",
    "                        sub_df = df.loc[df[colu].notna(), colu]\n",
    "\n",
    "                        for patient in sub_df.index:\n",
    "                            result_df[cohort].loc[patient, i] = 1 # rank one for the patients that have measurements for the feature        \n",
    "                \n",
    "\n",
    "        # replace the patient ids with 0 to n for data protection \n",
    "        result_df[cohort].set_index(np.arange(0, len(result_df[cohort])), inplace=True)\n",
    "        result_df[cohort].index.name = 'ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create empty dictionaries of dataframes to store the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of dataframes (one dataframe per modality)\n",
    "feature_availability = {name: pd.DataFrame(index = all_features[name]['Feature'], columns = all_cohort_names) for name in all_features.keys()}\n",
    "\n",
    "# combine all the feature tables (modalities) into one big dataframe  \n",
    "combined_mapping = pd.concat(all_features, ignore_index=False)\n",
    "# make a dictionary with cohorts as key and empty dataframe as values with all mapped features for columns of each cohort\n",
    "patient_vs_feature = {name: pd.DataFrame(columns = combined_mapping.loc[combined_mapping[name].notna(), 'Feature']) for name in combined_mapping.columns[1:21]}\n",
    "\n",
    "\n",
    "# make a dictionary of dataframes where modalities are the keys and dataframes are the value\n",
    "num_patients_per_visit = {name: pd.DataFrame(columns = all_features[name]['Feature']) for name in all_features.keys()}\n",
    "\n",
    "for moda in num_patients_per_visit:\n",
    "    \n",
    "    for cohort in cohort_studies:\n",
    "        # make a list of visit timepoints for each cohort\n",
    "        vis_num = list(Counter(cohort_studies[cohort]['Months'].loc[cohort_studies[cohort]['Months'].notna()]))\n",
    "        \n",
    "        # write the cohort name and visit month as index\n",
    "        for vis in vis_num:\n",
    "            num_patients_per_visit[moda].loc[cohort + '__' + str(vis)] = np.nan\n",
    "            \n",
    "            \n",
    "# divide the name and timepoints and store it into separated columns\n",
    "for modal in num_patients_per_visit:\n",
    "    num_patients_per_visit[modal]['cohorts'] = num_patients_per_visit[modal].index\n",
    "    num_patients_per_visit[modal][['Cohort', 'Months']] = num_patients_per_visit[modal]['cohorts'].str.split('__', 1, expand=True)\n",
    "    num_patients_per_visit[modal].drop(columns=['cohorts'], inplace=True) # set the cohort names as index\n",
    "    num_patients_per_visit[modal] = num_patients_per_visit[modal].set_index('Cohort')\n",
    "    \n",
    "# change the month column to numeric     \n",
    "for moda in num_patients_per_visit:\n",
    "    num_patients_per_visit[moda]['Months'] = num_patients_per_visit[moda]['Months'].astype(str).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_per_feature(all_features, cohort_studies, num_patients_per_visit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_features = feature_exist(all_features, cohort_studies, feature_availability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_measurment_availability(combined_mapping, cohort_studies, patient_vs_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write to tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modal in num_patients_per_visit:\n",
    "    num_patients_per_visit[modal].to_csv(\"number_of_patient_per_visit/\" + f\"{modal}.tsv\", sep='\\t', index_label='Cohort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modal in feature_availability:\n",
    "    feature_availability[modal].to_csv(\"feature_availability_in_cohorts/\" + f\"{modal}.tsv\", sep='\\t', index_label='Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in patient_vs_feature:\n",
    "    patient_vs_feature[cohort].to_csv(\"feature_vs_patient_per_cohort/\" + f\"{cohort}.tsv\", sep='\\t', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_features.to_csv(\"feature_availability_in_cohorts/nonexistence_features.tsv\", sep='\\t', index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
